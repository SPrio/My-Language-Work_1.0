{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#library used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=list()\n",
    "b=str(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dictionary</th>\n",
       "      <th>এক ধরণের বই, যাতে একটি নির্দিষ্ট ভাষার শব্দসমূহ বর্ণানুক্রমে তালিকাভূক্ত থাকে এবং শব্দসমূহের অর্থ, উচ্চারণ, ব্যূৎপত্তি, ব্যবহার ইত্যাদি বর্ণিত ও ব্যাখ্যায়িত থাকে।</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abb</td>\n",
       "      <td>পড়েন (N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alps</td>\n",
       "      <td>সুইজারল্যাণ্ডের গিরিশ্রেণীবিশেষ (N), আল্প্স (N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>americanism</td>\n",
       "      <td>মার্কিনিপনা (N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anglophilia</td>\n",
       "      <td>ইংরেজপ্রীতি</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aristotelian</td>\n",
       "      <td>অ্যারিস্টটলের শিষ্য (N), গ্রীক পণ্ডিত অ্যারিস্...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dictionary  \\\n",
       "0           abb   \n",
       "1          alps   \n",
       "2   americanism   \n",
       "3   anglophilia   \n",
       "4  aristotelian   \n",
       "\n",
       "  এক ধরণের বই, যাতে একটি নির্দিষ্ট ভাষার শব্দসমূহ বর্ণানুক্রমে তালিকাভূক্ত থাকে এবং শব্দসমূহের অর্থ, উচ্চারণ, ব্যূৎপত্তি, ব্যবহার ইত্যাদি বর্ণিত ও ব্যাখ্যায়িত থাকে।  \\\n",
       "0                                          পড়েন (N)                                                                                                                    \n",
       "1    সুইজারল্যাণ্ডের গিরিশ্রেণীবিশেষ (N), আল্প্স (N)                                                                                                                    \n",
       "2                                    মার্কিনিপনা (N)                                                                                                                    \n",
       "3                                        ইংরেজপ্রীতি                                                                                                                    \n",
       "4  অ্যারিস্টটলের শিষ্য (N), গ্রীক পণ্ডিত অ্যারিস্...                                                                                                                    \n",
       "\n",
       "  Unnamed: 2 Unnamed: 3  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df=pd.read_csv('BengaliDictionary_36.csv')\n",
    "except:\n",
    "    url=('https://raw.githubusercontent.com/MinhasKamal/BengaliDictionary/master/BengaliDictionary_36.csv')\n",
    "    df=pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'CC'),\n",
       " ('now', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('something', 'NN'),\n",
       " ('completely', 'RB'),\n",
       " ('different', 'JJ')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = word_tokenize(\"And now for something completely different\")\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('am', 'VBP'), ('going', 'VBG'), ('to', 'TO'), ('school', 'NN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_txt=word_tokenize('I am going to school')\n",
    "pos_tag(my_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dictionary</th>\n",
       "      <th>এক ধরণের বই, যাতে একটি নির্দিষ্ট ভাষার শব্দসমূহ বর্ণানুক্রমে তালিকাভূক্ত থাকে এবং শব্দসমূহের অর্থ, উচ্চারণ, ব্যূৎপত্তি, ব্যবহার ইত্যাদি বর্ণিত ও ব্যাখ্যায়িত থাকে।</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abb</td>\n",
       "      <td>পড়েন (N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alps</td>\n",
       "      <td>সুইজারল্যাণ্ডের গিরিশ্রেণীবিশেষ (N), আল্প্স (N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>americanism</td>\n",
       "      <td>মার্কিনিপনা (N)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anglophilia</td>\n",
       "      <td>ইংরেজপ্রীতি</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aristotelian</td>\n",
       "      <td>অ্যারিস্টটলের শিষ্য (N), গ্রীক পণ্ডিত অ্যারিস্...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dictionary  \\\n",
       "0           abb   \n",
       "1          alps   \n",
       "2   americanism   \n",
       "3   anglophilia   \n",
       "4  aristotelian   \n",
       "\n",
       "  এক ধরণের বই, যাতে একটি নির্দিষ্ট ভাষার শব্দসমূহ বর্ণানুক্রমে তালিকাভূক্ত থাকে এবং শব্দসমূহের অর্থ, উচ্চারণ, ব্যূৎপত্তি, ব্যবহার ইত্যাদি বর্ণিত ও ব্যাখ্যায়িত থাকে।  \\\n",
       "0                                          পড়েন (N)                                                                                                                    \n",
       "1    সুইজারল্যাণ্ডের গিরিশ্রেণীবিশেষ (N), আল্প্স (N)                                                                                                                    \n",
       "2                                    মার্কিনিপনা (N)                                                                                                                    \n",
       "3                                        ইংরেজপ্রীতি                                                                                                                    \n",
       "4  অ্যারিস্টটলের শিষ্য (N), গ্রীক পণ্ডিত অ্যারিস্...                                                                                                                    \n",
       "\n",
       "  Unnamed: 2 Unnamed: 3  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 2', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 3', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dictionary</th>\n",
       "      <th>এক ধরণের বই, যাতে একটি নির্দিষ্ট ভাষার শব্দসমূহ বর্ণানুক্রমে তালিকাভূক্ত থাকে এবং শব্দসমূহের অর্থ, উচ্চারণ, ব্যূৎপত্তি, ব্যবহার ইত্যাদি বর্ণিত ও ব্যাখ্যায়িত থাকে।</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abb</td>\n",
       "      <td>পড়েন (N)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alps</td>\n",
       "      <td>সুইজারল্যাণ্ডের গিরিশ্রেণীবিশেষ (N), আল্প্স (N)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>americanism</td>\n",
       "      <td>মার্কিনিপনা (N)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anglophilia</td>\n",
       "      <td>ইংরেজপ্রীতি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aristotelian</td>\n",
       "      <td>অ্যারিস্টটলের শিষ্য (N), গ্রীক পণ্ডিত অ্যারিস্...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dictionary  \\\n",
       "0           abb   \n",
       "1          alps   \n",
       "2   americanism   \n",
       "3   anglophilia   \n",
       "4  aristotelian   \n",
       "\n",
       "  এক ধরণের বই, যাতে একটি নির্দিষ্ট ভাষার শব্দসমূহ বর্ণানুক্রমে তালিকাভূক্ত থাকে এবং শব্দসমূহের অর্থ, উচ্চারণ, ব্যূৎপত্তি, ব্যবহার ইত্যাদি বর্ণিত ও ব্যাখ্যায়িত থাকে।  \n",
       "0                                          পড়েন (N)                                                                                                                   \n",
       "1    সুইজারল্যাণ্ডের গিরিশ্রেণীবিশেষ (N), আল্প্স (N)                                                                                                                   \n",
       "2                                    মার্কিনিপনা (N)                                                                                                                   \n",
       "3                                        ইংরেজপ্রীতি                                                                                                                   \n",
       "4  অ্যারিস্টটলের শিষ্য (N), গ্রীক পণ্ডিত অ্যারিস্...                                                                                                                   "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'আমি (Pro.), অহং (Pro.), আমা (Pro.)'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['dictionary'] == 'i', 'এক ধরণের বই, যাতে একটি নির্দিষ্ট ভাষার শব্দসমূহ বর্ণানুক্রমে তালিকাভূক্ত থাকে এবং শব্দসমূহের অর্থ, উচ্চারণ, ব্যূৎপত্তি, ব্যবহার ইত্যাদি বর্ণিত ও ব্যাখ্যায়িত থাকে।'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16301    আমি (Pro.), অহং (Pro.), আমা (Pro.)\n",
       "Name: এক ধরণের বই, যাতে একটি নির্দিষ্ট ভাষার শব্দসমূহ বর্ণানুক্রমে তালিকাভূক্ত থাকে এবং শব্দসমূহের অর্থ, উচ্চারণ, ব্যূৎপত্তি, ব্যবহার ইত্যাদি বর্ণিত ও ব্যাখ্যায়িত থাকে।, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('dictionary==\\'i\\'')['এক ধরণের বই, যাতে একটি নির্দিষ্ট ভাষার শব্দসমূহ বর্ণানুক্রমে তালিকাভূক্ত থাকে এবং শব্দসমূহের অর্থ, উচ্চারণ, ব্যূৎপত্তি, ব্যবহার ইত্যাদি বর্ণিত ও ব্যাখ্যায়িত থাকে।']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dictionary',\n",
       " 'এক ধরণের বই, যাতে একটি নির্দিষ্ট ভাষার শব্দসমূহ বর্ণানুক্রমে তালিকাভূক্ত থাকে এবং শব্দসমূহের অর্থ, উচ্চারণ, ব্যূৎপত্তি, ব্যবহার ইত্যাদি বর্ণিত ও ব্যাখ্যায়িত থাকে।']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.columns=['english','bengali']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>bengali</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abb</td>\n",
       "      <td>পড়েন (N)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alps</td>\n",
       "      <td>সুইজারল্যাণ্ডের গিরিশ্রেণীবিশেষ (N), আল্প্স (N)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>americanism</td>\n",
       "      <td>মার্কিনিপনা (N)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anglophilia</td>\n",
       "      <td>ইংরেজপ্রীতি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aristotelian</td>\n",
       "      <td>অ্যারিস্টটলের শিষ্য (N), গ্রীক পণ্ডিত অ্যারিস্...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        english                                            bengali\n",
       "0           abb                                          পড়েন (N)\n",
       "1          alps    সুইজারল্যাণ্ডের গিরিশ্রেণীবিশেষ (N), আল্প্স (N)\n",
       "2   americanism                                    মার্কিনিপনা (N)\n",
       "3   anglophilia                                        ইংরেজপ্রীতি\n",
       "4  aristotelian  অ্যারিস্টটলের শিষ্য (N), গ্রীক পণ্ডিত অ্যারিস্..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Supriyo', 'Mahanta']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1='Supriyo Mahanta'\n",
    "x=text1.split(' ')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16301    আমি (Pro.), অহং (Pro.), আমা (Pro.)\n",
       "Name: bengali, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.query('english==\\'i\\'')['bengali']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1040    এর পরে ম\n",
       "Name: bengali, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.query('english==\\'am\\'')['bengali']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14472    চলা, যাওয়া, গমন করা, ছেড়ে যাওয়া, বিদায় হওয়া, এ...\n",
       "Name: bengali, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.query('english==\\'go\\'')['bengali']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33908    থেকে (Prep.), জন্য (Prep.), কাছে (Prep.), পর্য...\n",
       "Name: bengali, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.query('english==\\'to\\'')['bengali']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30453    ইস্কুল, পাঠশালা, শিক্ষালয়\n",
       "Name: bengali, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.query('english==\\'school\\'')['bengali']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'চলা, যাওয়া, গমন করা, ছেড়ে যাওয়া, বিদায় হওয়া, এগোনো, তেজ'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[df1['english']=='go','bengali'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('am', 'VBP'), ('going', 'VBG'), ('to', 'TO'), ('school', 'NN')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_txt=word_tokenize('I am going to school')\n",
    "token_list=pos_tag(my_txt)\n",
    "token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token_list[0:1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PRP'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list[0:1][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'PRP')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def rule1(temp_token_list):\n",
    "    i=0\n",
    "    if(temp_token_list[i:i+1][i][i+1]=='PRP' and temp_token_list[i+1:i+2][i][i+1]=='VBP'):\n",
    "        del temp_token_list[i+1:i+2]\n",
    "        \n",
    "    return temp_token_list\n",
    "\n",
    "token=list([('i', 'PRP'), ('am', 'VBP')])\n",
    "token_list1=rule1(token)\n",
    "token_list1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'আমি'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#token[0:1][0][0]\n",
    "((df1.loc[df1['english']==token_list1[0][0],'bengali'].iloc[0]).split(',')[0]).split(' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import nltk.corpus.indian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('am', 'VBP'), ('going', 'VBG'), ('to', 'TO'), ('school', 'NN')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_txt2=word_tokenize('to school')\n",
    "token_list=pos_tag(my_txt)\n",
    "token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ইস্কুলএ\n"
     ]
    }
   ],
   "source": [
    "def rule2(token_txt):\n",
    "    i=0\n",
    "    if(token_txt[i:i+1][i][i+1]=='TO' and token_txt[i+1:i+2][i][i+1]=='NN'):\n",
    "        del token_txt[i:i+1]\n",
    "    s1=(df1.loc[df1['english']=='school','bengali'].iloc[0]).split(',')[0]\n",
    "    s1=s1+'এ'\n",
    "    return s1\n",
    "tk=[('to', 'TO'), ('school', 'NN')]\n",
    "print(rule2(tk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Approach 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text which u wamt to translate->I am going to school\n",
      "the bengali meaning-> আমি   ইস্কুলএ   চলা\n"
     ]
    }
   ],
   "source": [
    "from nltk import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#csv reading \n",
    "try:\n",
    "    df=pd.read_csv('BengaliDictionary_36.csv')\n",
    "except:\n",
    "    url=('https://raw.githubusercontent.com/MinhasKamal/BengaliDictionary/master/BengaliDictionary_36.csv')\n",
    "    df=pd.read_csv(url)\n",
    " \n",
    "#print(df.head())\n",
    "\n",
    "df2=df.copy()\n",
    "df2 = df2.drop('Unnamed: 2', 1)\n",
    "df2 = df2.drop('Unnamed: 3', 1)\n",
    "df2.columns=['english','bengali']\n",
    "#taking the english word which we want to convert into bengali\n",
    "text1=input(\"Enter the text which u wamt to translate->\")\n",
    "\n",
    "#using POS tagger dividing the sentence as per its class\n",
    "token_list1=word_tokenize(text1)\n",
    "token_list2=pos_tag(token_list1)\n",
    "\n",
    "#to evaluate the meaning of the text\n",
    "#break the list in three segments\n",
    "list1=token_list2[0:2]\n",
    "list2=token_list2[2:3]\n",
    "list3=token_list2[3:]\n",
    "\n",
    "# then rules are applied on the stence to evaluate the meaning\n",
    "#rule1 - for getting I am ->I\n",
    "def rule1(temp_token_list):\n",
    "    i=0\n",
    "    if(temp_token_list[i:i+1][i][i+1]=='PRP' and temp_token_list[i+1:i+2][i][i+1]=='VBP'):\n",
    "        del temp_token_list[i+1:i+2]\n",
    "    s1=temp_token_list[i:i+1][i][i]\n",
    "    s2=((df2.loc[df2['english']==s1.lower(),'bengali'].iloc[0]).split(',')[0]).split(' ')[0]\n",
    "    return s2\n",
    "\n",
    "b1=rule1(list1)\n",
    "\n",
    "if(list2[0:1][0][0].lower()=='going'):\n",
    "    b2=(df2.loc[df2['english']=='go','bengali'].iloc[0]).split(',')[0]\n",
    "\n",
    "#rule-2 - for to school-> school e\n",
    "def rule2(token_txt):\n",
    "    i=0\n",
    "    if(token_txt[i:i+1][i][i+1]=='TO' and token_txt[i+1:i+2][i][i+1]=='NN'):\n",
    "        del token_txt[i:i+1]\n",
    "    s1=(df2.loc[df2['english']=='school','bengali'].iloc[0]).split(',')[0]\n",
    "    s1=s1+'এ'\n",
    "    return s1\n",
    "\n",
    "b3=rule2(list3)\n",
    "\n",
    "\n",
    "print(\"the bengali meaning->\",b1,\" \",b3,\" \",b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENG</th>\n",
       "      <th>BENG</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>আমি</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YOU</td>\n",
       "      <td>তুমি</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://conjugator.reverso.net/conjugation-engl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HE</td>\n",
       "      <td>সে</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHE</td>\n",
       "      <td>সে</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ENG  BENG  Unnamed: 2  Unnamed: 3  Unnamed: 4  Unnamed: 5  \\\n",
       "0  NaN   NaN         NaN         NaN         NaN         NaN   \n",
       "1    I   আমি         NaN         NaN         NaN         NaN   \n",
       "2  YOU  তুমি         NaN         NaN         NaN         NaN   \n",
       "3   HE    সে         NaN         NaN         NaN         NaN   \n",
       "4  SHE    সে         NaN         NaN         NaN         NaN   \n",
       "\n",
       "                                          Unnamed: 6  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2  http://conjugator.reverso.net/conjugation-engl...  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_me=pd.read_csv('a.csv')\n",
    "df_me.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('are', 'VBP'), ('am', 'VBP'), ('is', 'VBZ'), ('has', 'VBZ'), ('have', 'VBN'), ('had', 'VBN'), ('has', 'VBZ'), ('been', 'VBN'), ('be', 'VB'), ('will', 'MD'), ('was', 'VBD'), ('shall', 'MD'), ('it', 'PRP'), ('I', 'PRP'), ('you', 'PRP'), ('he', 'PRP'), ('she', 'PRP'), ('they', 'PRP'), ('go', 'VBP'), ('went', 'VBD'), ('gone', 'VBN')]\n",
      "\n",
      "[('I', 'PRP'), ('will', 'MD'), ('be', 'VB'), ('going', 'VBG'), ('there', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "token_list1=word_tokenize('are am is has have had has been be will was shall it I you he she they go went gone')\n",
    "token_list2=pos_tag(token_list1)\n",
    "print(token_list2)\n",
    "print()\n",
    "token_list1=word_tokenize('I will be going there')\n",
    "token_list2=pos_tag(token_list1)\n",
    "print(token_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Approach 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>beng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>আমি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YOU</td>\n",
       "      <td>তুমি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HE</td>\n",
       "      <td>সে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHE</td>\n",
       "      <td>সে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WE</td>\n",
       "      <td>আমরা</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>THEY</td>\n",
       "      <td>তারা</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IT</td>\n",
       "      <td>এটা, যে, এই, তিনি, সে, এমন, এইগুলো, তারা, সেগুলো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AM</td>\n",
       "      <td>হই-Aux-Present-1st_Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IS</td>\n",
       "      <td>হই-Aux-Present-3rd_Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ARE</td>\n",
       "      <td>হই-Aux-Present-2nd_Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WAS</td>\n",
       "      <td>হল-Aux-Past-Singular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WERE</td>\n",
       "      <td>হল-Aux-Past-Plural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WILL BE</td>\n",
       "      <td>হবে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SHALL BE</td>\n",
       "      <td>হবে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HAS</td>\n",
       "      <td>ইয়।ছে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HAS BEEN</td>\n",
       "      <td>ইয়।তেছি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HAVE</td>\n",
       "      <td>ইয়।ছে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HAVE BEEN</td>\n",
       "      <td>ইয়।তেছি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HAD</td>\n",
       "      <td>ইয়।ছিল</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HAD BEEN</td>\n",
       "      <td>ইয়।তেছিল</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GO</td>\n",
       "      <td>য।য়-Simple_Present-1st_Person,য।য়-Simple_Prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GONE</td>\n",
       "      <td>গিয়।ছি-Present/Future_Perfect-1st_Person,গিয়।ছ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GOES</td>\n",
       "      <td>য।য়-Simple_Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WENT</td>\n",
       "      <td>যেত।ম(Simple_Past-1st_Person),যেতে(Simple_Past...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>TO</td>\n",
       "      <td>এতে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SCHOOL</td>\n",
       "      <td>বিদ্যালয়</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GOING</td>\n",
       "      <td>যাচ্ছি-Present_Continuous-1st_Person,য।চ্ছ-Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EXPECTING</td>\n",
       "      <td>আশা করছি-Present_Continuous-1st_Person,আশা করছ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>FROM</td>\n",
       "      <td>থেকে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ME</td>\n",
       "      <td>আমার</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>WHAT</td>\n",
       "      <td>কি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>THE</td>\n",
       "      <td>টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PEN</td>\n",
       "      <td>পেন</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GIVE</td>\n",
       "      <td>দিলাম-Simple_Present-1st_Person,দাও-Simple_Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SAUVIK</td>\n",
       "      <td>সৌভিক</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MOVES</td>\n",
       "      <td>চলে য।য়-Simple_Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>JAIPUR</td>\n",
       "      <td>জয়পুর</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>HIGH</td>\n",
       "      <td>উচ্চ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AFTER</td>\n",
       "      <td>পরে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MEET</td>\n",
       "      <td>সাক্ষাৎ করি-Simple_Present-1st_Person,সাক্ষাৎ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>CLASS</td>\n",
       "      <td>ক্লাস</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PAST</td>\n",
       "      <td>পেরিয়ে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>FIVE</td>\n",
       "      <td>পাঁচ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>THREE</td>\n",
       "      <td>তিন</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SCHEDULED</td>\n",
       "      <td>নির্ধারিত</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>FOR</td>\n",
       "      <td>জন্য</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>COACHING</td>\n",
       "      <td>কোচিং</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>COLLEGE</td>\n",
       "      <td>কলেজ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SOME</td>\n",
       "      <td>কিছু</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>TIME</td>\n",
       "      <td>সময়</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>FARMLAND</td>\n",
       "      <td>কৃষিজমি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>SO</td>\n",
       "      <td>খুব</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>COOL</td>\n",
       "      <td>শান্ত</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>DOG</td>\n",
       "      <td>কুকুর</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>GOOD</td>\n",
       "      <td>ভাল</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BOY</td>\n",
       "      <td>ছেলে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>A</td>\n",
       "      <td>একটি</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          eng                                               beng\n",
       "0           I                                                আমি\n",
       "1         YOU                                               তুমি\n",
       "2          HE                                                 সে\n",
       "3         SHE                                                 সে\n",
       "4          WE                                               আমরা\n",
       "5        THEY                                               তারা\n",
       "6          IT   এটা, যে, এই, তিনি, সে, এমন, এইগুলো, তারা, সেগুলো\n",
       "7          AM                          হই-Aux-Present-1st_Person\n",
       "8          IS                          হই-Aux-Present-3rd_Person\n",
       "9         ARE                          হই-Aux-Present-2nd_Person\n",
       "10        WAS                               হল-Aux-Past-Singular\n",
       "11       WERE                                 হল-Aux-Past-Plural\n",
       "12    WILL BE                                                হবে\n",
       "13   SHALL BE                                                হবে\n",
       "14       HAS                                               ইয়।ছে\n",
       "15   HAS BEEN                                            ইয়।তেছি\n",
       "16       HAVE                                              ইয়।ছে\n",
       "17  HAVE BEEN                                            ইয়।তেছি\n",
       "18        HAD                                             ইয়।ছিল\n",
       "19   HAD BEEN                                           ইয়।তেছিল\n",
       "20         GO  য।য়-Simple_Present-1st_Person,য।য়-Simple_Prese...\n",
       "21       GONE  গিয়।ছি-Present/Future_Perfect-1st_Person,গিয়।ছ...\n",
       "22       GOES                                 য।য়-Simple_Present\n",
       "23       WENT  যেত।ম(Simple_Past-1st_Person),যেতে(Simple_Past...\n",
       "24         TO                                                এতে\n",
       "25     SCHOOL                                          বিদ্যালয়\n",
       "26      GOING  যাচ্ছি-Present_Continuous-1st_Person,য।চ্ছ-Pre...\n",
       "27  EXPECTING  আশা করছি-Present_Continuous-1st_Person,আশা করছ...\n",
       "28       FROM                                               থেকে\n",
       "29         ME                                               আমার\n",
       "30       WHAT                                                 কি\n",
       "31        THE                                                 টি\n",
       "32        PEN                                                পেন\n",
       "33       GIVE  দিলাম-Simple_Present-1st_Person,দাও-Simple_Pre...\n",
       "34     SAUVIK                                              সৌভিক\n",
       "35      MOVES                             চলে য।য়-Simple_Present\n",
       "36     JAIPUR                                             জয়পুর\n",
       "37       HIGH                                               উচ্চ\n",
       "38      AFTER                                                পরে\n",
       "39       MEET  সাক্ষাৎ করি-Simple_Present-1st_Person,সাক্ষাৎ ...\n",
       "40      CLASS                                              ক্লাস\n",
       "41       PAST                                             পেরিয়ে\n",
       "42       FIVE                                               পাঁচ\n",
       "43      THREE                                                তিন\n",
       "44  SCHEDULED                                          নির্ধারিত\n",
       "45        FOR                                               জন্য\n",
       "46   COACHING                                              কোচিং\n",
       "47    COLLEGE                                               কলেজ\n",
       "48       SOME                                               কিছু\n",
       "49       TIME                                               সময়\n",
       "50   FARMLAND                                            কৃষিজমি\n",
       "51         SO                                                খুব\n",
       "52       COOL                                              শান্ত\n",
       "53        DOG                                              কুকুর\n",
       "54       GOOD                                                ভাল\n",
       "55        BOY                                               ছেলে\n",
       "56          A                                               একটি"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#csv reading\n",
    "\n",
    "df_xls=pd.read_excel('E_to_B_xls_ownmade.xlsx')\n",
    "df_xls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['এটা, যে, এই, তিনি, সে, এমন, এইগুলো, তারা, সেগুলো']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li=list(df_xls.loc[df_xls['eng']=='IT','beng']) \n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I YOU HE SHE WE THEY IT AM IS ARE WAS WERE WILL BE SHALL BE HAS  HAS BEEN HAVE HAVE BEEN HAD HAD BEEN GO GOING  GONE GOES WENT TO SCHOOL '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=''\n",
    "for i in range(0,len(df_xls['eng'])):\n",
    "               s=s+df_xls['eng'][i]+' '\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YOU</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HE</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHE</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WE</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0    I  PRP\n",
       "1  YOU  VBP\n",
       "2   HE  PRP\n",
       "3  SHE   MD\n",
       "4   WE  VBZ"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_s=word_tokenize(s)\n",
    "token_s=pos_tag(token_s)\n",
    "pd.DataFrame(token_s).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('মহিষের', 'NN'), ('সন্তান', 'NN'), (':', 'SYM'), ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.indian.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#text2.common_contexts([\"monstrous\", \"very\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>play</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>violin</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hope</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>see</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>you</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tomorrow</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>She</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>studying</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>English</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>English</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>an</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>International</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>language</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>We</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>do</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>not</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>do</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bad</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>things</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Everybody</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>know</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>english</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>I</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>am</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>going</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>school</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0    1\n",
       "0               I  PRP\n",
       "1             can   MD\n",
       "2            play   VB\n",
       "3             the   DT\n",
       "4          violin   NN\n",
       "5             and   CC\n",
       "6              We  PRP\n",
       "7            hope  VBP\n",
       "8              to   TO\n",
       "9             see   VB\n",
       "10            you  PRP\n",
       "11       tomorrow   NN\n",
       "12            and   CC\n",
       "13            She  PRP\n",
       "14             is  VBZ\n",
       "15       studying  VBG\n",
       "16        English  NNP\n",
       "17            and   CC\n",
       "18        English  NNP\n",
       "19             is  VBZ\n",
       "20             an   DT\n",
       "21  International  NNP\n",
       "22       language   NN\n",
       "23            and   CC\n",
       "24             We  PRP\n",
       "25             do  VBP\n",
       "26            not   RB\n",
       "27             do   VB\n",
       "28            bad   JJ\n",
       "29         things  NNS\n",
       "30            and   CC\n",
       "31      Everybody  NNP\n",
       "32           know  VBP\n",
       "33        english   JJ\n",
       "34            and   CC\n",
       "35              I  PRP\n",
       "36             am  VBP\n",
       "37          going  VBG\n",
       "38             to   TO\n",
       "39         school   NN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking Declarative sentences\n",
    "\n",
    "token_s=word_tokenize('I can play the violin and We hope to see you tomorrow and She is studying English and English is an International language and We do not do bad things and Everybody know english and I am going to school')\n",
    "token_s=pos_tag(token_s)\n",
    "pd.DataFrame(token_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('আমরা', 'JJ'),\n",
       " ('খারাপ', 'NNP'),\n",
       " ('জিনিস', 'NNP'),\n",
       " ('করি', 'NNP'),\n",
       " ('না', 'NN')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_s=word_tokenize('আমরা খারাপ জিনিস করি না')\n",
    "token_s=pos_tag(token_s)\n",
    "token_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['After', 'the', 'high', 'school', ',', 'Sauvik', 'moves', 'to', 'Jaipur']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('After', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('high', 'JJ'),\n",
       " ('school', 'NN'),\n",
       " (',', ','),\n",
       " ('Sauvik', 'NNP'),\n",
       " ('moves', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('Jaipur', 'VB')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_s=word_tokenize('After the high school,Sauvik moves to Jaipur')\n",
    "print(token_s)\n",
    "token_s=pos_tag(token_s)\n",
    "token_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pip install grammar-check\n",
    "#pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2B with Interface and popup messege"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Assertive Sentence\n",
      "So the input text is:  You are a good boy\n",
      "POS tagging and Word Categorizing\n",
      "word_class:  ['You', 'are', 'a', 'good', 'boy']\n",
      "token_class:  ['PRP', 'VBP', 'DT', 'JJ', 'NN']\n",
      "Subject:  ['You'] Verb:  ['are'] Object:  ['a', 'good', 'boy']\n",
      "After Reconstructing the Sentence it wil  be like:  ['You', 'a', 'good', 'boy', 'are']\n",
      "The English sentence is:  You are a good boy\n",
      "The Bengali meaning is:  ['তুমি', 'একটি', 'ভাল', 'ছেলে']\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "label1 = Label( root, text=\"Enter Text\")\n",
    "E1 = Entry(root, bd =10)\n",
    "\n",
    "def getText():\n",
    "    #print (E1.get())\n",
    "    txt_new=str(E1.get())\n",
    "    txt_indiv=txt_new.split(' ')\n",
    "    txt_test=txt_new\n",
    "    print('For Assertive Sentence')\n",
    "    print('So the input text is: ',txt_test)\n",
    "    print('POS tagging and Word Categorizing')\n",
    "    token_txt_test=word_tokenize(txt_test)\n",
    "    token_txt_test=pos_tag(token_txt_test)\n",
    "    word_class=list(pd.DataFrame(token_txt_test)[0])\n",
    "    print('word_class: ',word_class)\n",
    "    token_class=list(pd.DataFrame(token_txt_test)[1])\n",
    "    print('token_class: ',token_class)\n",
    "    Subject=list()\n",
    "    Verb=list()\n",
    "    Object=list()\n",
    "\n",
    "\n",
    "    i=0\n",
    "    while(i<len(token_txt_test)):\n",
    "        if(token_class[i]=='PRP' or token_class[i]=='NNP' or token_class[i]=='DT' or token_class[i]=='PRP$' or token_class[i]=='NN' or token_class[i]=='IN' or token_class[i]=='TO' or token_class[i]=='JJ' or token_class[i]=='NNS'):\n",
    "            Subject.append(word_class[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "    while(i<len(token_txt_test)):\n",
    "        if(token_class[i] == 'RB' or token_class[i] == 'MD' or token_class[i]=='VB' or token_class[i]=='VBP' or token_class[i]=='VBZ' or token_class[i]=='VBG' or token_class[i]=='VBN'):\n",
    "            Verb.append(word_class[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "    while(i<len(token_txt_test)):\n",
    "        if(token_class[i]=='DT' or token_class[i]=='NN' or token_class[i]=='NNP' or token_class[i]=='JJ' or token_class[i]=='NNS' or token_class[i]=='TO' or token_class[i]=='IN' or token_class[i]=='PRP' or token_class[i]=='RB' or token_class[i]=='JJ'):\n",
    "            Object.append(word_class[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print('Subject: ',Subject,'Verb: ',Verb,'Object: ',Object)\n",
    "    try:\n",
    "        Beng_line=Subject+Object+Verb\n",
    "        print(\"After Reconstructing the Sentence it wil  be like: \",Beng_line)\n",
    "        Beng_mean=list()\n",
    "        list_1=list()\n",
    "        str_1=''\n",
    "        #meaning creation \n",
    "        person=''\n",
    "        i=0\n",
    "        while(i<len(Subject)):\n",
    "            str_1=str(df_xls.loc[df_xls['eng']==Subject[i].upper(),'beng']).split(' ')[4].split('\\n')[0]\n",
    "            #print(str_1.split(' ')[4].split('\\n'))\n",
    "            Beng_mean.append(str_1)\n",
    "            if(Subject[i] == 'He' or Subject[i] == 'She'  or Subject[i] == 'They'):\n",
    "                person='3rd_Person'\n",
    "            if(Subject[i] == 'I' or Subject[i] == 'We'):\n",
    "                person='1st_Person'\n",
    "            if(Subject[i] == 'You'):\n",
    "                person='2nd_Person'\n",
    "            i+=1\n",
    "        i=0\n",
    "        if(check_class(Object[i])=='TO' or check_class(Object[i])=='IN'):\n",
    "                Object += [Object.pop(0)]\n",
    "                #print(Object)\n",
    "                #Object.insert(len(Object)-1, list1.pop(0))\n",
    "        #print(Object)\n",
    "        while(i<len(Object)):\n",
    "            str_1=str(df_xls.loc[df_xls['eng']==Object[i].upper(),'beng']).split(' ')[4].split('\\n')[0]\n",
    "            #print(str_1.split(' ')[4].split('\\n'))\n",
    "            Beng_mean.append(str_1)\n",
    "            i+=1\n",
    "\n",
    "\n",
    "        i=0\n",
    "        #for am ,i ,are\n",
    "        Pres_Aux=0\n",
    "        Past_Aux=0\n",
    "        Fut_Aux=0\n",
    "        #print(df_xls.loc[df_xls['eng']==Verb[i].upper(),'beng'])\n",
    "        while(i<len(Verb)):\n",
    "            list_1=list(df_xls.loc[df_xls['eng']==Verb[i].upper(),'beng'])\n",
    "            str1 = ''.join(list_1)\n",
    "            #print(str1)\n",
    "            #print(type(list_1))\n",
    "            list_2=list()\n",
    "            if(check_class(Verb[i])=='VBP'):\n",
    "                list_2=str1.split(',')\n",
    "                #print(list_2)\n",
    "                if(i>=0):\n",
    "                    #print('enter if i>=0')\n",
    "                    list_3=list()\n",
    "                    for i1 in range(0,len(list_2)):\n",
    "                        #print('enter in the loop')\n",
    "                        list_3=list_2[i1].split('-')\n",
    "                        #print(list_3)\n",
    "                        if(list_3[1]=='Simple_Present'):\n",
    "                            if(list_3[2]==person):\n",
    "                                Beng_mean.append(list_3[0])\n",
    "                        if(list_3[1]=='Aux'):\n",
    "                            if(list_3[2]=='Present'):\n",
    "                                Pres_Aux=1\n",
    "                            #if(list_3[2]=='Past'):\n",
    "                                #Past_Aux=1\n",
    "\n",
    "\n",
    "            if(check_class(Verb[i])=='VBZ'):\n",
    "                list_2=[i.split(',', 1)[0] for i in list_1]\n",
    "                #list_2=str1.split(',')\n",
    "                #print(type(list_2[0]))\n",
    "                if(i>=0):\n",
    "                    #print('enter if i>=0')\n",
    "                    list_3=list()\n",
    "                    for i1 in range(0,len(list_2)):\n",
    "                        #print('enter in the loop')\n",
    "                        list_3=list_2[i1].split('-')\n",
    "                        #print(list_3)\n",
    "                        if(list_3[1]=='Aux'):\n",
    "                            if(list_3[2]=='Present'):\n",
    "                                Pres_Aux=1\n",
    "                            if(list_3[2]=='Past'):\n",
    "                                Past_Aux=1\n",
    "                        if(list_3[1]=='Simple_Present'):\n",
    "                            Beng_mean.append(list_3[0]) \n",
    "                        if(list_3[1]=='Present/Future_Continuous'):\n",
    "                            Beng_mean.append(list_3[0])\n",
    "            if(check_class(Verb[i])=='VBG'):\n",
    "                list_2=str1.split(',')\n",
    "                #print(list_2)\n",
    "                if(i>=0):\n",
    "                    #print('enter if i>=0')\n",
    "                    list_3=list()\n",
    "                    for i1 in range(0,len(list_2)):\n",
    "                        #print('enter in the loop')\n",
    "                        list_3=list_2[i1].split('-')\n",
    "                        #print(list_3)\n",
    "                        if(list_3[1]=='Present_Continuous'):\n",
    "                            if(list_3[2]==person):\n",
    "                                Beng_mean.append(list_3[0])\n",
    "\n",
    "            i+=1\n",
    "        #normal meaning finding\n",
    "        '''i=0\n",
    "        while(i<len(Beng_line)):\n",
    "            Beng_mean.append(df_xls.loc[df_xls['eng']==Beng_line[i].upper(),'beng'])\n",
    "            i+=1'''\n",
    "        print(\"The English sentence is: \",txt_test)\n",
    "        print(\"The Bengali meaning is: \",Beng_mean)\n",
    "        \n",
    "        def onclick():\n",
    "            pass\n",
    "\n",
    "        root = Tk()\n",
    "        text = Text(root)\n",
    "        text.insert(INSERT, Beng_mean)\n",
    "        text.pack()\n",
    "\n",
    "    except Exception as exp:\n",
    "        print(exp)\n",
    "    \n",
    "submit = Button(root, text =\"Submit\", command = getText)\n",
    "\n",
    "label1.pack()\n",
    "E1.pack()\n",
    "\n",
    "submit.pack(side =BOTTOM) \n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Assertive Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the text: You are a good boy\n",
      "For Assertive Sentence\n",
      "So the input text is:  You are a good boy\n"
     ]
    }
   ],
   "source": [
    "#print (E1.get())\n",
    "#txt_new=str(E1.get())\n",
    "\n",
    "txt_new=input('enter the text: ')\n",
    "txt_indiv=txt_new.split(' ')\n",
    "txt_test=txt_new\n",
    "'''#txt_list=list()\n",
    "i=0\n",
    "while(i<len(txt_indiv)):\n",
    "    #txt_list.append(txt_indiv[i].lower()+' ')\n",
    "    txt_test+=txt_indiv[i].lower()+' '\n",
    "    i+=1\n",
    "txt_test=txt_test.strip(' ')'''\n",
    "print('For Assertive Sentence')\n",
    "print('So the input text is: ',txt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging and Word Categorizing\n",
      "word_class:  ['You', 'are', 'a', 'good', 'boy']\n",
      "token_class:  ['PRP', 'VBP', 'DT', 'JJ', 'NN']\n",
      "Subject:  ['You'] Verb:  ['are'] Object:  ['a', 'good', 'boy']\n"
     ]
    }
   ],
   "source": [
    "print('POS tagging and Word Categorizing')\n",
    "token_txt_test=word_tokenize(txt_test)\n",
    "token_txt_test=pos_tag(token_txt_test)\n",
    "word_class=list(pd.DataFrame(token_txt_test)[0])\n",
    "print('word_class: ',word_class)\n",
    "token_class=list(pd.DataFrame(token_txt_test)[1])\n",
    "print('token_class: ',token_class)\n",
    "Subject=list()\n",
    "Verb=list()\n",
    "Object=list()\n",
    "\n",
    "\n",
    "i=0\n",
    "while(i<len(token_txt_test)):\n",
    "    if('/' in word_class[i]):\n",
    "            if(word_class[i].split('/')[1]=='NAME'):\n",
    "                Subject.append(word_class[i].split('/')[0])\n",
    "                i+=1\n",
    "    elif(token_class[i]=='PRP' or token_class[i]=='NNP' or token_class[i]=='DT' or token_class[i]=='PRP$' or token_class[i]=='NN' or token_class[i]=='IN' or token_class[i]=='TO' or token_class[i]=='JJ' or token_class[i]=='NNS'):\n",
    "        Subject.append(word_class[i])\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "while(i<len(token_txt_test)):\n",
    "    if(token_class[i] == 'MD' or token_class[i]=='VB' or token_class[i]=='VBP' or token_class[i]=='VBZ' or token_class[i]=='VBG' or token_class[i]=='VBN'):\n",
    "        Verb.append(word_class[i])\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "while(i<len(token_txt_test)):\n",
    "    if('/' in word_class[i]):\n",
    "            if(word_class[i].split('/')[1]=='NAME'):\n",
    "                Object.append(word_class[i].split('/')[0])\n",
    "                i+=1\n",
    "    elif(token_class[i]=='VB' or token_class[i]=='VBN' or token_class[i]=='CD' or token_class[i]=='DT' or token_class[i]=='NN' or token_class[i]=='NNP' or token_class[i]=='JJ' or token_class[i]=='NNS' or token_class[i]=='TO' or token_class[i]=='IN' or token_class[i]=='PRP' or token_class[i]=='RB' or token_class[i]=='JJ'):\n",
    "        Object.append(word_class[i])\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "print('Subject: ',Subject,'Verb: ',Verb,'Object: ',Object)\n",
    "#not working\n",
    "#1- after high school sauvik moves to jaipur\n",
    "#2- The dog is so cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def phase_check(st):\n",
    "    st=st.split(',')\n",
    "    for i in range(0,len(st)):\n",
    "        sub_str=st[i].split(' ')\n",
    "        for j in range(0,len(sub_str)-1):\n",
    "            if(check(sub_str[j])==check(sub_str[j+1])):\n",
    "                print(1)\n",
    "                \n",
    "        \n",
    "st=\"Go to the coaching class,after the class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'error: not found'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_class(str):\n",
    "    for i in range(0,len(token_class)):\n",
    "        if(word_class[i] == str):\n",
    "            return token_class[i]\n",
    "    return 'error: not found'\n",
    "check_class('am')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Reconstructing the Sentence it will be like:  ['You', 'a', 'good', 'boy', 'are']\n",
      "The English sentence is:  You are a good boy\n",
      "The Bengali meaning is:  ['তুমি', 'একটি', 'ভাল', 'ছেলে']\n"
     ]
    }
   ],
   "source": [
    "    Beng_line=Subject+Object+Verb\n",
    "    print(\"After Reconstructing the Sentence it will be like: \",Beng_line)\n",
    "    Beng_mean=list()\n",
    "    list_1=list()\n",
    "    str_1=''\n",
    "    #meaning creation \n",
    "    person=''\n",
    "    i=0\n",
    "    if(check_class(Subject[i])=='TO' or check_class(Subject[i])=='IN' or check_class(Subject[i])=='DT'):\n",
    "            Subject += [Subject.pop(0)]\n",
    "    while(i<len(Subject)):\n",
    "        str_1=str(df_xls.loc[df_xls['eng']==Subject[i].upper(),'beng']).split(' ')[4].split('\\n')[0]\n",
    "        #print(str_1.split(' ')[4].split('\\n'))\n",
    "        Beng_mean.append(str_1)\n",
    "        if(Subject[i] == 'He' or Subject[i] == 'She'  or Subject[i] == 'They'):\n",
    "            person='3rd_Person'\n",
    "        if(Subject[i] == 'I' or Subject[i] == 'We'):\n",
    "            person='1st_Person'\n",
    "        if(Subject[i] == 'You'):\n",
    "            person='2nd_Person'\n",
    "        i+=1\n",
    "    i=0\n",
    "    if(check_class(Object[i])=='TO' or check_class(Object[i])=='IN'):\n",
    "            Object += [Object.pop(0)]\n",
    "            #print(Object)\n",
    "            #Object.insert(len(Object)-1, list1.pop(0))\n",
    "    #print(Object)\n",
    "    while(i<len(Object)):\n",
    "        str_1=str(df_xls.loc[df_xls['eng']==Object[i].upper(),'beng']).split(' ')[4].split('\\n')[0]\n",
    "        #print(str_1.split(' ')[4].split('\\n'))\n",
    "        Beng_mean.append(str_1)\n",
    "        i+=1\n",
    "    \n",
    "    \n",
    "    i=0\n",
    "    #for am ,i ,are\n",
    "    Pres_Aux=0\n",
    "    Past_Aux=0\n",
    "    Fut_Aux=0\n",
    "    #print(df_xls.loc[df_xls['eng']==Verb[i].upper(),'beng'])\n",
    "    while(i<len(Verb)):\n",
    "        list_1=list(df_xls.loc[df_xls['eng']==Verb[i].upper(),'beng'])\n",
    "        str1 = ''.join(list_1)\n",
    "        #print(str1)\n",
    "        #print(type(list_1))\n",
    "        list_2=list()\n",
    "        if(check_class(Verb[i])=='VBP'):\n",
    "            list_2=str1.split(',')\n",
    "            #print(list_2)\n",
    "            if(i>=0):\n",
    "                #print('enter if i>=0')\n",
    "                list_3=list()\n",
    "                for i1 in range(0,len(list_2)):\n",
    "                    #print('enter in the loop')\n",
    "                    list_3=list_2[i1].split('-')\n",
    "                    #print(list_3)#VBP\n",
    "                    if(len(list_3)==1):\n",
    "                        Beng_mean.append(list_3[0]) \n",
    "                    elif(list_3[1]=='Simple_Present'):\n",
    "                        if(list_3[2]==person):\n",
    "                            Beng_mean.append(list_3[0])\n",
    "                    elif(list_3[1]=='Aux'):\n",
    "                        if(list_3[2]=='Present'):\n",
    "                            Pres_Aux=1\n",
    "                        #if(list_3[2]=='Past'):\n",
    "                            #Past_Aux=1\n",
    "\n",
    "\n",
    "        if(check_class(Verb[i])=='VBZ'):\n",
    "            list_2=[i.split(',', 1)[0] for i in list_1]\n",
    "            #list_2=str1.split(',')\n",
    "            #print(type(list_2[0]))\n",
    "            if(i>=0):\n",
    "                #print('enter if i>=0')\n",
    "                list_3=list()\n",
    "                for i1 in range(0,len(list_2)):\n",
    "                    #print('enter in the loop')\n",
    "                    list_3=list_2[i1].split('-')\n",
    "                    #print(list_3)\n",
    "                    if(list_3[1]=='Aux'):\n",
    "                        if(list_3[2]=='Present'):\n",
    "                            Pres_Aux=1\n",
    "                        if(list_3[2]=='Past'):\n",
    "                            Past_Aux=1\n",
    "                    if(list_3[1]=='Simple_Present'):\n",
    "                        Beng_mean.append(list_3[0]) \n",
    "                    if(list_3[1]=='Present/Future_Continuous'):\n",
    "                        Beng_mean.append(list_3[0])\n",
    "        if(check_class(Verb[i])=='VBG'):\n",
    "            list_2=str1.split(',')\n",
    "            #print(list_2)\n",
    "            if(i>=0):\n",
    "                #print('enter if i>=0')\n",
    "                list_3=list()\n",
    "                for i1 in range(0,len(list_2)):\n",
    "                    #print('enter in the loop')\n",
    "                    list_3=list_2[i1].split('-')\n",
    "                    #print(list_3)\n",
    "                    if(list_3[1]=='Present_Continuous'):\n",
    "                        if(list_3[2]==person):\n",
    "                            Beng_mean.append(list_3[0])\n",
    "                   \n",
    "        i+=1\n",
    "    #normal meaning finding\n",
    "    '''i=0\n",
    "    while(i<len(Beng_line)):\n",
    "        Beng_mean.append(df_xls.loc[df_xls['eng']==Beng_line[i].upper(),'beng'])\n",
    "        i+=1'''\n",
    "    print(\"The English sentence is: \",txt_test)\n",
    "    print(\"The Bengali meaning is: \",Beng_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Interrogative Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'going', 'to', 'school']\n",
      "['PRP', 'VBP', 'VBG', 'TO', 'NN']\n"
     ]
    }
   ],
   "source": [
    "token_txt_test=word_tokenize(txt_test)\n",
    "token_txt_test=pos_tag(token_txt_test)\n",
    "word_class=list(pd.DataFrame(token_txt_test)[0])\n",
    "print(word_class)\n",
    "token_class=list(pd.DataFrame(token_txt_test)[1])\n",
    "print(token_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "#Parse tree\n",
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\")\n",
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "parser = nltk.ChartParser(groucho_grammar)\n",
    "for tree in parser.parse(sent):\n",
    "     print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('How', 'WRB'), ('is', 'VBZ'), ('your', 'PRP$'), ('business', 'NN'), ('going', 'VBG'), ('on', 'IN')]\n",
      "[('Who', 'WP'), ('fixed', 'VBD'), ('the', 'DT'), ('computer', 'NN')]\n",
      "[('Whom', 'NNP'), ('do', 'VBP'), ('you', 'PRP'), ('support', 'VB')]\n",
      "[('What', 'WP'), ('are', 'VBP'), ('you', 'PRP'), ('expecting', 'VBG'), ('from', 'IN'), ('me', 'PRP')]\n",
      "[('What', 'WP'), ('time', 'NN'), ('is', 'VBZ'), ('it', 'PRP'), ('now', 'RB')]\n",
      "[('How', 'WRB'), ('many', 'JJ'), ('people', 'NNS'), ('have', 'VBP'), ('died', 'VBN'), ('there', 'EX')]\n"
     ]
    }
   ],
   "source": [
    "#wh_words testing\n",
    "wh_testing=word_tokenize('How is your business going on')\n",
    "wh_testing=pos_tag(wh_testing)\n",
    "print(wh_testing)\n",
    "wh_testing=word_tokenize('Who fixed the computer')\n",
    "wh_testing=pos_tag(wh_testing)\n",
    "print(wh_testing)\n",
    "wh_testing=word_tokenize('Whom do you support')\n",
    "wh_testing=pos_tag(wh_testing)\n",
    "print(wh_testing)\n",
    "wh_testing=word_tokenize('What are you expecting from me')\n",
    "wh_testing=pos_tag(wh_testing)\n",
    "print(wh_testing)\n",
    "wh_testing=word_tokenize('What time is it now')\n",
    "wh_testing=pos_tag(wh_testing)\n",
    "print(wh_testing)\n",
    "wh_testing=word_tokenize('How many people have died there')\n",
    "wh_testing=pos_tag(wh_testing)\n",
    "print(wh_testing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E2B with Interface and popup messege for ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Interogative Sentence\n",
      "So the input text is:  What are you expecting from me\n",
      "POS tagging and Word Categorizing\n",
      "What are you expecting from me\n",
      "word_class:  ['What', 'are', 'you', 'expecting', 'from', 'me']\n",
      "token_class:  ['WP', 'VBP', 'PRP', 'VBG', 'IN', 'PRP']\n",
      "WH-words:  ['What'] Subject:  ['you'] Verb:  ['are', 'expecting'] Object:  ['from', 'me']\n",
      "After Reconstructing the Sentence it wil  be like:  ['you', 'from', 'me', 'are', 'expecting', 'What']\n",
      "The English sentence is:  What are you expecting from me\n",
      "The Bengali meaning is:  ['তুমি', 'আমার', 'থেকে', 'কি', 'আশা করছ']\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "For Interogative Sentence\n",
      "So the input text is:  What are you expecting from me?\n",
      "POS tagging and Word Categorizing\n",
      "What are you expecting from me?\n",
      "word_class:  ['What', 'are', 'you', 'expecting', 'from', 'me', '?']\n",
      "token_class:  ['WP', 'VBP', 'PRP', 'VBG', 'IN', 'PRP', '.']\n",
      "WH-words:  ['What'] Subject:  ['you'] Verb:  ['are', 'expecting'] Object:  ['from', 'me', '?']\n",
      "After Reconstructing the Sentence it wil  be like:  ['you', 'from', 'me', '?', 'are', 'expecting', 'What']\n",
      "The English sentence is:  What are you expecting from me?\n",
      "The Bengali meaning is:  ['তুমি', 'আমার', 'object)', 'থেকে', 'কি', 'আশা করছ']\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "label1 = Label( root, text=\"Enter Text\")\n",
    "E1 = Entry(root, bd =10, width=60)\n",
    "root.title('Input')\n",
    "\n",
    "def getText():\n",
    "    #print (E1.get())\n",
    "    txt_new=str(E1.get())\n",
    "    txt_indiv=txt_new.split(' ')\n",
    "    txt_test=txt_new\n",
    "    print('For Interogative Sentence')\n",
    "    print('So the input text is: ',txt_test)\n",
    "    print('POS tagging and Word Categorizing')\n",
    "    print(txt_test)\n",
    "    token_txt_test=word_tokenize(txt_test)\n",
    "    token_txt_test=pos_tag(token_txt_test)\n",
    "    word_class=list(pd.DataFrame(token_txt_test)[0])\n",
    "    print('word_class: ',word_class)\n",
    "    token_class=list(pd.DataFrame(token_txt_test)[1])\n",
    "    print('token_class: ',token_class)\n",
    "    WH=list()\n",
    "    Subject=list()\n",
    "    Verb=list()\n",
    "    Object=list()\n",
    "\n",
    "\n",
    "    i=0\n",
    "    while(i<len(token_txt_test)):\n",
    "        if(token_class[i]=='WRB' or token_class[i]=='WP'):\n",
    "            WH.append(word_class[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "    while(i<len(token_txt_test)):\n",
    "        if(token_class[i]=='DT' or token_class[i]=='NN' or token_class[i]=='NNP' or token_class[i]=='JJ' or token_class[i]=='NNS' or token_class[i]=='TO' or token_class[i]=='IN' or token_class[i]=='PRP' or token_class[i]=='RB' or token_class[i]=='JJ'):\n",
    "            Object.append(word_class[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            break        \n",
    "    while(i<len(token_txt_test)):\n",
    "        if(token_class[i] == 'MD' or token_class[i]=='VB' or token_class[i]=='VBP' or token_class[i]=='VBZ' or token_class[i]=='VBG' or token_class[i]=='VBN'):\n",
    "            Verb.append(word_class[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "    while(i<len(token_txt_test)):\n",
    "        if(token_class[i]=='EX' or token_class[i]=='PRP' or token_class[i]=='NNP' or token_class[i]=='DT' or token_class[i]=='PRP$' or token_class[i]=='NN' or token_class[i]=='IN' or token_class[i]=='TO' or token_class[i]=='JJ' or token_class[i]=='NNS'):\n",
    "            Subject.append(word_class[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "    while(i<len(token_txt_test)):\n",
    "        if(token_class[i]=='RB' or token_class[i] == 'MD' or token_class[i]=='VB' or token_class[i]=='VBP' or token_class[i]=='VBZ' or token_class[i]=='VBG' or token_class[i]=='VBN' or token_class[i]=='VBD'):\n",
    "            Verb.append(word_class[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    while(i<len(token_txt_test)):\n",
    "        if(token_class[i]=='DT' or token_class[i]=='NN' or token_class[i]=='NNP' or token_class[i]=='JJ' or token_class[i]=='NNS' or token_class[i]=='TO' or token_class[i]=='IN' or token_class[i]=='PRP' or token_class[i]=='RB' or token_class[i]=='JJ'):\n",
    "            Object.append(word_class[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            Object.append(word_class[i])\n",
    "            i+=1\n",
    "\n",
    "    print('WH-words: ',WH,'Subject: ',Subject,'Verb: ',Verb,'Object: ',Object)\n",
    "    #not working-'Whom', 'do', 'you', 'support'\n",
    "   \n",
    "    Beng_line=Subject+Object+Verb+WH\n",
    "    print(\"After Reconstructing the Sentence it wil  be like: \",Beng_line)\n",
    "    Beng_mean=list()\n",
    "    list_1=list()\n",
    "    str_1=''\n",
    "    #meaning creation \n",
    "    person=''\n",
    "\n",
    "    i=0\n",
    "    \n",
    "    while(i<len(Subject)):\n",
    "        #print(df_xls.loc[df_xls['eng']==Subject[i].upper(),'beng'])\n",
    "        str_1=str(df_xls.loc[df_xls['eng']==Subject[i].upper(),'beng']).split(' ')[4].split('\\n')[0]\n",
    "        #print(str_1.split(' ')[4].split('\\n'))\n",
    "        Beng_mean.append(str_1)\n",
    "        if(Subject[i] == 'they' or Subject[i] == 'she' or Subject[i] == 'he'):\n",
    "            person='3rd_Person'\n",
    "        if(Subject[i] == 'we' or Subject[i] == 'I'):\n",
    "            person='1st_Person'\n",
    "        if(Subject[i] == 'you'):\n",
    "            person='2nd_Person'\n",
    "        i+=1\n",
    "    i=0\n",
    "    if(len(Object)>=1):\n",
    "        if(check_class(Object[i])=='TO' or check_class(Object[i])=='IN'):\n",
    "                Object += [Object.pop(0)]\n",
    "            #print(Object)\n",
    "            #Object.insert(len(Object)-1, list1.pop(0))\n",
    "    #print(Object)\n",
    "    while(i<len(Object)):\n",
    "        str_1=str(df_xls.loc[df_xls['eng']==Object[i].upper(),'beng']).split(' ')[4].split('\\n')[0]\n",
    "        #print(str_1.split(' ')[4].split('\\n'))\n",
    "        Beng_mean.append(str_1)\n",
    "        i+=1\n",
    "    i=0\n",
    "    while(i<len(WH)):\n",
    "        #print(df_xls.loc[df_xls['eng']==WH[i].upper(),'beng'])\n",
    "        str_1=str(df_xls.loc[df_xls['eng']==WH[i].upper(),'beng']).split(' ')[4].split('\\n')[0]\n",
    "        #print(str_1.split(' ')[4].split('\\n'))\n",
    "        Beng_mean.append(str_1)\n",
    "        i+=1 \n",
    "    \n",
    "    i=0\n",
    "    #for am ,i ,are\n",
    "    Pres_Aux=0\n",
    "    Past_Aux=0\n",
    "    Fut_Aux=0\n",
    "    #print(len(Verb))\n",
    "    #print(df_xls.loc[df_xls['eng']==Verb[i].upper(),'beng'])\n",
    "    while(i<len(Verb)):\n",
    "        list_1=list(df_xls.loc[df_xls['eng']==Verb[i].upper(),'beng'])\n",
    "        str1 = ''.join(list_1)\n",
    "        #print(str1)\n",
    "        #print(type(list_1))\n",
    "        list_2=list()\n",
    "        if(check_class(Verb[i])=='VBP'):\n",
    "            list_2=str1.split(',')\n",
    "            #print(list_2)\n",
    "            if(i>=0):\n",
    "                #print('enter if i>=0')\n",
    "                list_3=list()\n",
    "                for i1 in range(0,len(list_2)):\n",
    "                    #print('enter in the loop')\n",
    "                    list_3=list_2[i1].split('-')\n",
    "                    #print(list_3)\n",
    "                    if(list_3[1]=='Simple_Present'):\n",
    "                        #print('Sim pre')\n",
    "                        if(list_3[2]==person):\n",
    "                            Beng_mean.append(list_3[0])\n",
    "                    if(list_3[1]=='Aux'):\n",
    "                        #print('Aux')\n",
    "                        if(list_3[2]=='Present'):\n",
    "                            Pres_Aux=1\n",
    "                        #if(list_3[2]=='Past'):\n",
    "                            #Past_Aux=1\n",
    "\n",
    "\n",
    "        if(check_class(Verb[i])=='VBZ'):\n",
    "            list_2=[i.split(',', 1)[0] for i in list_1]\n",
    "            #list_2=str1.split(',')\n",
    "            #print(type(list_2[0]))\n",
    "            if(i>=0):\n",
    "                #print('enter if i>=0')\n",
    "                list_3=list()\n",
    "                for i1 in range(0,len(list_2)):\n",
    "                    #print('enter in the loop')\n",
    "                    list_3=list_2[i1].split('-')\n",
    "                    #print(list_3)\n",
    "                    if(list_3[1]=='Aux'):\n",
    "                        if(list_3[2]=='Present'):\n",
    "                            Pres_Aux=1\n",
    "                        if(list_3[2]=='Past'):\n",
    "                            Past_Aux=1\n",
    "                    if(list_3[1]=='Simple_Present'):\n",
    "                        Beng_mean.append(list_3[0]) \n",
    "                    if(list_3[1]=='Present_Continuous'):\n",
    "                        if(Pres_Aux==1):\n",
    "                            Beng_mean.append(list_3[0])\n",
    "        if(check_class(Verb[i])=='VBG'):\n",
    "            list_2=str1.split(',')\n",
    "            #print(list_2)\n",
    "            if(i>=0):\n",
    "                #print('enter if i>=0')\n",
    "                list_3=list()\n",
    "                for i1 in range(0,len(list_2)):\n",
    "                    #print('enter in the loop')\n",
    "                    list_3=list_2[i1].split('-')\n",
    "                    #print('VBG',list_3[1])\n",
    "                    #print(person)\n",
    "                    if(list_3[1]=='Present_Continuous'):\n",
    "                        if(list_3[2]==person):\n",
    "                            if(Pres_Aux==1):\n",
    "                                Beng_mean.append(list_3[0])\n",
    "                   \n",
    "        i+=1\n",
    "   \n",
    "    #normal meaning finding\n",
    "    '''i=0\n",
    "    while(i<len(Beng_line)):\n",
    "        Beng_mean.append(df_xls.loc[df_xls['eng']==Beng_line[i].upper(),'beng'])\n",
    "        i+=1'''\n",
    "    print(\"The English sentence is: \",txt_test)\n",
    "    print(\"The Bengali meaning is: \",Beng_mean)\n",
    "    Beng_string=''\n",
    "    for ii in Beng_mean:\n",
    "                print(type(ii))\n",
    "                ii=str(ii).rstrip('}')\n",
    "                ii=str(ii).lstrip('{')\n",
    "                Beng_string += str(ii)+' '\n",
    "        \n",
    "    def onclick():\n",
    "        pass\n",
    "\n",
    "    root1 = Tk()\n",
    "    text = Text(root1)\n",
    "    root1.title('Output')\n",
    "    text.insert(INSERT, Beng_string)\n",
    "    \n",
    "    text.pack()\n",
    "\n",
    "    \n",
    "    \n",
    "submit = Button(root, text =\"Submit\", command = getText)\n",
    "\n",
    "label1.pack()\n",
    "E1.pack()\n",
    "\n",
    "submit.pack(side =BOTTOM) \n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Interrogative Question\n",
      "Enter the sentence: What are you expecting from me\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What are you expecting from me'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('For Interrogative Question')\n",
    "txt_test=input('Enter the sentence: ')\n",
    "txt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging and Word Categorizing\n",
      "What are you expecting from me\n",
      "word_class:  ['What', 'are', 'you', 'expecting', 'from', 'me']\n",
      "token_class:  ['WP', 'VBP', 'PRP', 'VBG', 'IN', 'PRP']\n",
      "WH-words:  ['What'] Subject:  ['you'] Verb:  ['are', 'expecting'] Object:  ['from', 'me']\n"
     ]
    }
   ],
   "source": [
    "print('POS tagging and Word Categorizing')\n",
    "print(txt_test)\n",
    "token_txt_test=word_tokenize(txt_test)\n",
    "token_txt_test=pos_tag(token_txt_test)\n",
    "word_class=list(pd.DataFrame(token_txt_test)[0])\n",
    "print('word_class: ',word_class)\n",
    "token_class=list(pd.DataFrame(token_txt_test)[1])\n",
    "print('token_class: ',token_class)\n",
    "WH=list()\n",
    "Subject=list()\n",
    "Verb=list()\n",
    "Object=list()\n",
    "wh_flag=0\n",
    "\n",
    "\n",
    "i=0\n",
    "while(i<len(token_txt_test)):\n",
    "    if(token_class[i]=='WRB' or token_class[i]=='WP'):\n",
    "        WH.append(word_class[i])\n",
    "        wh_flag=1\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "while(i<len(token_txt_test)):\n",
    "    if(token_class[i]=='DT' or token_class[i]=='NN' or token_class[i]=='NNP' or token_class[i]=='JJ' or token_class[i]=='NNS' or token_class[i]=='TO' or token_class[i]=='IN' or token_class[i]=='PRP' or token_class[i]=='RB' or token_class[i]=='JJ'):\n",
    "        Object.append(word_class[i])\n",
    "        i+=1\n",
    "    else:\n",
    "        break        \n",
    "while(i<len(token_txt_test)):\n",
    "    if(token_class[i] == 'MD' or token_class[i]=='VB' or token_class[i]=='VBP' or token_class[i]=='VBZ' or token_class[i]=='VBG' or token_class[i]=='VBN'):\n",
    "        Verb.append(word_class[i])\n",
    "        wh_flag=1\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "while(i<len(token_txt_test)):\n",
    "    if(token_class[i]=='EX' or token_class[i]=='PRP' or token_class[i]=='NNP' or token_class[i]=='DT' or token_class[i]=='PRP$' or token_class[i]=='NN' or token_class[i]=='IN' or token_class[i]=='TO' or token_class[i]=='JJ' or token_class[i]=='NNS'):\n",
    "        Subject.append(word_class[i])\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "while(i<len(token_txt_test)):\n",
    "    if(token_class[i]=='RB' or token_class[i] == 'MD' or token_class[i]=='VB' or token_class[i]=='VBP' or token_class[i]=='VBZ' or token_class[i]=='VBG' or token_class[i]=='VBN' or token_class[i]=='VBD'):\n",
    "        Verb.append(word_class[i])\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "while(i<len(token_txt_test)):\n",
    "    if(token_class[i]=='DT' or token_class[i]=='NN' or token_class[i]=='NNP' or token_class[i]=='JJ' or token_class[i]=='NNS' or token_class[i]=='TO' or token_class[i]=='IN' or token_class[i]=='PRP' or token_class[i]=='RB' or token_class[i]=='JJ'):\n",
    "        Object.append(word_class[i])\n",
    "        i+=1\n",
    "    else:\n",
    "        Object.append(word_class[i])\n",
    "        i+=1\n",
    "        \n",
    "print('WH-words: ',WH,'Subject: ',Subject,'Verb: ',Verb,'Object: ',Object)\n",
    "#not working-'Whom', 'do', 'you', 'support'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Reconstructing the Sentence it wil  be like:  ['you', 'from', 'me', 'are', 'expecting', 'What']\n",
      "The English sentence is:  What are you expecting from me\n",
      "The Bengali meaning is:  ['তুমি', 'আমার', 'থেকে', 'কি', 'আশা করছ']\n"
     ]
    }
   ],
   "source": [
    "    Beng_line=Subject+Object+Verb+WH\n",
    "    print(\"After Reconstructing the Sentence it wil  be like: \",Beng_line)\n",
    "    Beng_mean=list()\n",
    "    list_1=list()\n",
    "    str_1=''\n",
    "    #meaning creation \n",
    "    person=''\n",
    "\n",
    "    i=0\n",
    "    \n",
    "    while(i<len(Subject)):\n",
    "        #print(df_xls.loc[df_xls['eng']==Subject[i].upper(),'beng'])\n",
    "        str_1=str(df_xls.loc[df_xls['eng']==Subject[i].upper(),'beng']).split(' ')[4].split('\\n')[0]\n",
    "        #print(str_1.split(' ')[4].split('\\n'))\n",
    "        Beng_mean.append(str_1)\n",
    "        if(Subject[i] == 'they' or Subject[i] == 'she' or Subject[i] == 'he'):\n",
    "            person='3rd_Person'\n",
    "        if(Subject[i] == 'we' or Subject[i] == 'I'):\n",
    "            person='1st_Person'\n",
    "        if(Subject[i] == 'you'):\n",
    "            person='2nd_Person'\n",
    "        i+=1\n",
    "    i=0\n",
    "    if(len(Object)>=1):\n",
    "        if(check_class(Object[i])=='TO' or check_class(Object[i])=='IN'):\n",
    "                Object += [Object.pop(0)]\n",
    "            #print(Object)\n",
    "            #Object.insert(len(Object)-1, list1.pop(0))\n",
    "    #print(Object)\n",
    "    while(i<len(Object)):\n",
    "        str_1=str(df_xls.loc[df_xls['eng']==Object[i].upper(),'beng']).split(' ')[4].split('\\n')[0]\n",
    "        '''#print(str_1)\n",
    "        #print(str_1.split(' ')[len(str_1)-1].split('\\n'))\n",
    "        str_1_type1=str_1.split(',')\n",
    "        str_1_type_string=\"\"\n",
    "        #print(str_1_type1)\n",
    "        for i1 in range(0,len(str_1_type1)):\n",
    "            str_1_type=str(str_1_type1).split('-')\n",
    "            str_1_type_string=str(str_1_type)\n",
    "            #str_1_type = ''.join(str_1_type1)\n",
    "            str_1_type_string = str_1_type_string.rstrip('\\\"]')\n",
    "            str_1_type_string = str_1_type_string.lstrip('[\\\"')\n",
    "            \n",
    "            str_1_type = ''\n",
    "            for ii in str_1_type1:\n",
    "                str_1_type +=str(ii)\n",
    "            #print('check 1')\n",
    "            #print(len(str_1_type))\n",
    "            #print(str_1_type_string)\n",
    "            str_1_type_string=str_1_type_string.split(',')\n",
    "            str_1_type_string_list=list()\n",
    "            for i2 in range(len(str_1_type_string)):\n",
    "                str_1_type_string_list.append(str_1_type_string[i2])\n",
    "            if(len(str_1_type_string_list[i1])>1):\n",
    "                print('check 2')\n",
    "                if(str_1_type[i1][1]=='Interrogative'):\n",
    "                    print('check 3')\n",
    "                    Beng_mean.append(str_1_type[i1][0])\n",
    "            else:   \n",
    "                print('check 3')\n",
    "                Beng_mean.append(str_1_type[i1][0])'''\n",
    "        Beng_mean.append(str_1)\n",
    "        i+=1\n",
    "    i=0\n",
    "    while(i<len(WH)):\n",
    "        #print(df_xls.loc[df_xls['eng']==WH[i].upper(),'beng'])\n",
    "        str_1=str(df_xls.loc[df_xls['eng']==WH[i].upper(),'beng']).split(' ')[4].split('\\n')[0]\n",
    "        #print(str_1.split(' ')[4].split('\\n'))\n",
    "        Beng_mean.append(str_1)\n",
    "        i+=1 \n",
    "    \n",
    "    i=0\n",
    "    #for am ,i ,are\n",
    "    Pres_Aux=0\n",
    "    Past_Aux=0\n",
    "    Fut_Aux=0\n",
    "    #print(len(Verb))\n",
    "    #print(df_xls.loc[df_xls['eng']==Verb[i].upper(),'beng'])\n",
    "    while(i<len(Verb)):\n",
    "        list_1=list(df_xls.loc[df_xls['eng']==Verb[i].upper(),'beng'])\n",
    "        str1 = ''.join(list_1)\n",
    "        #print(str1)\n",
    "        #print(type(list_1))\n",
    "        list_2=list()\n",
    "        if(check_class(Verb[i])=='VBP'):\n",
    "            list_2=str1.split(',')\n",
    "            #print(list_2)\n",
    "            if(i>=0):\n",
    "                #print('enter if i>=0')\n",
    "                list_3=list()\n",
    "                for i1 in range(0,len(list_2)):\n",
    "                    #print('enter in the loop')\n",
    "                    list_3=list_2[i1].split('-')\n",
    "                    #print(list_3)\n",
    "                    if(list_3[1]=='Simple_Present'):\n",
    "                        #print('Sim pre')\n",
    "                        if(list_3[2]==person):\n",
    "                            Beng_mean.append(list_3[0])\n",
    "                    if(list_3[1]=='Aux'):\n",
    "                        #print('Aux')\n",
    "                        if(list_3[2]=='Present'):\n",
    "                            Pres_Aux=1\n",
    "                        #if(list_3[2]=='Past'):\n",
    "                            #Past_Aux=1\n",
    "\n",
    "\n",
    "        if(check_class(Verb[i])=='VBZ'):\n",
    "            list_2=[i.split(',', 1)[0] for i in list_1]\n",
    "            #list_2=str1.split(',')\n",
    "            #print(type(list_2[0]))\n",
    "            if(i>=0):\n",
    "                #print('enter if i>=0')\n",
    "                list_3=list()\n",
    "                for i1 in range(0,len(list_2)):\n",
    "                    #print('enter in the loop')\n",
    "                    list_3=list_2[i1].split('-')\n",
    "                    #print(list_3)\n",
    "                    if(list_3[1]=='Aux'):\n",
    "                        if(list_3[2]=='Present'):\n",
    "                            Pres_Aux=1\n",
    "                        if(list_3[2]=='Past'):\n",
    "                            Past_Aux=1\n",
    "                    if(list_3[1]=='Simple_Present'):\n",
    "                        Beng_mean.append(list_3[0]) \n",
    "                    if(list_3[1]=='Present_Continuous'):\n",
    "                        if(Pres_Aux==1):\n",
    "                            Beng_mean.append(list_3[0])\n",
    "        if(check_class(Verb[i])=='VBG'):\n",
    "            list_2=str1.split(',')\n",
    "            #print(list_2)\n",
    "            if(i>=0):\n",
    "                #print('enter if i>=0')\n",
    "                list_3=list()\n",
    "                for i1 in range(0,len(list_2)):\n",
    "                    #print('enter in the loop')\n",
    "                    list_3=list_2[i1].split('-')\n",
    "                    #print('VBG',list_3[1])\n",
    "                    #print(person)\n",
    "                    if(list_3[1]=='Present_Continuous'):\n",
    "                        if(list_3[2]==person):\n",
    "                            if(Pres_Aux==1):\n",
    "                                Beng_mean.append(list_3[0])\n",
    "                   \n",
    "        i+=1\n",
    "   \n",
    "    #normal meaning finding\n",
    "    '''i=0\n",
    "    while(i<len(Beng_line)):\n",
    "        Beng_mean.append(df_xls.loc[df_xls['eng']==Beng_line[i].upper(),'beng'])\n",
    "        i+=1'''\n",
    "    print(\"The English sentence is: \",txt_test)\n",
    "    print(\"The Bengali meaning is: \",Beng_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcd\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = ['b','c','d']\n",
    "strng = ''\n",
    "for i in a:\n",
    "   strng +=str(i)\n",
    "print (strng)\n",
    "print(4%2 == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern: Subject (Invisible) + verb + object / where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('take', 'VB'), ('care', 'NN'), ('of', 'IN'), ('you', 'PRP')]\n",
      "[('give', 'VB'), ('me', 'PRP'), ('the', 'DT'), ('pen', 'NN')]\n",
      "[('do', 'VB'), ('it', 'PRP'), ('now', 'RB')]\n",
      "[('be', 'VB'), ('honest', 'JJS')]\n",
      "[('never', 'RB'), ('tell', 'VBP'), ('a', 'DT'), ('lie', 'NN')]\n",
      "[('do', 'VB'), ('not', 'RB'), ('laugh', 'RB'), ('at', 'IN'), ('other', 'JJ'), (\"'s\", 'POS'), ('helplessness', 'NN')]\n",
      "[('let', 'VB'), ('him', 'PRP'), ('go', 'VB'), ('there', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "#imprative testing\n",
    "wh_testing=word_tokenize('Take care of you')\n",
    "for i in range(0,len(wh_testing)):\n",
    "    wh_testing[i]=wh_testing[i].lower()\n",
    "wh_testing=pos_tag(wh_testing)\n",
    "print(wh_testing)\n",
    "wh_testing=word_tokenize('Give me the pen')\n",
    "for i in range(0,len(wh_testing)):\n",
    "    wh_testing[i]=wh_testing[i].lower()\n",
    "wh_testing=pos_tag(wh_testing)\n",
    "print(wh_testing)\n",
    "wh_testing=word_tokenize('Do it now')\n",
    "for i in range(0,len(wh_testing)):\n",
    "    wh_testing[i]=wh_testing[i].lower()\n",
    "wh_testing=pos_tag(wh_testing)\n",
    "print(wh_testing)\n",
    "wh_testing=word_tokenize('Be honest')\n",
    "for i in range(0,len(wh_testing)):\n",
    "    wh_testing[i]=wh_testing[i].lower()\n",
    "wh_testing=pos_tag(wh_testing)\n",
    "print(wh_testing)\n",
    "wh_testing=word_tokenize('Never tell a lie')\n",
    "for i in range(0,len(wh_testing)):\n",
    "    wh_testing[i]=wh_testing[i].lower()\n",
    "wh_testing=pos_tag(wh_testing)\n",
    "print(wh_testing)\n",
    "wh_testing=word_tokenize('Do not laugh at other\\'s helplessness')\n",
    "for i in range(0,len(wh_testing)):\n",
    "    wh_testing[i]=wh_testing[i].lower()\n",
    "wh_testing=pos_tag(wh_testing)\n",
    "print(wh_testing)\n",
    "wh_testing=word_tokenize('Let him go there')\n",
    "for i in range(0,len(wh_testing)):\n",
    "    wh_testing[i]=wh_testing[i].lower()\n",
    "wh_testing=pos_tag(wh_testing)\n",
    "print(wh_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Imperative Sentence\n",
      "Enter the sentence: go to coaching class after college\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'go to coaching class after college'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('For Imperative Sentence')\n",
    "txt_test=input('Enter the sentence: ')\n",
    "txt_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS tagging and Word Categorizing\n",
      "word_class:  ['go', 'to', 'coaching', 'class', 'after', 'the', 'college']\n",
      "token_class:  ['VB', 'TO', 'VBG', 'NN', 'IN', 'DT', 'NN']\n",
      "Verb:  ['go'] Object:  ['to', 'coaching', 'class', 'after', 'the', 'college']\n"
     ]
    }
   ],
   "source": [
    "print('POS tagging and Word Categorizing')\n",
    "token_txt_test=word_tokenize(txt_test)\n",
    "for i in range(0,len(token_txt_test)):\n",
    "    token_txt_test[i]=token_txt_test[i].lower()\n",
    "token_txt_test=pos_tag(token_txt_test)\n",
    "word_class=list(pd.DataFrame(token_txt_test)[0])\n",
    "print('word_class: ',word_class)\n",
    "token_class=list(pd.DataFrame(token_txt_test)[1])\n",
    "print('token_class: ',token_class)\n",
    "Subject=list()\n",
    "Verb=list()\n",
    "Object=list()\n",
    "\n",
    "\n",
    "i=0\n",
    "while(i<len(token_txt_test)):\n",
    "    if(token_class[i] == 'RB' or token_class[i] == 'MD' or token_class[i]=='VB' or token_class[i]=='VBP' or token_class[i]=='VBZ' or token_class[i]=='VBG' or token_class[i]=='VBN'):\n",
    "        Verb.append(word_class[i])\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "while(i<len(token_txt_test)):\n",
    "    if(token_class[i]=='VBG' or token_class[i]=='DT' or token_class[i]=='NN' or token_class[i]=='NNP' or token_class[i]=='JJ' or token_class[i]=='NNS' or token_class[i]=='TO' or token_class[i]=='IN' or token_class[i]=='PRP' or token_class[i]=='RB' or token_class[i]=='JJ'):\n",
    "        Object.append(word_class[i])\n",
    "        i+=1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "print('Verb: ',Verb,'Object: ',Object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Reconstructing the Sentence it wil  be like:  ['to', 'coaching', 'class', 'after', 'the', 'college', 'go']\n",
      "Object\n",
      "Object\n",
      "Object\n",
      "Object\n",
      "Object\n",
      "Object\n",
      "Verb\n",
      "The English sentence is:  go to coaching class after the college\n",
      "The Bengali meaning is:  ['কলেজ', 'টি', 'পরে', 'ক্লাস', 'কোচিং', 'এতে', 'যাও']\n"
     ]
    }
   ],
   "source": [
    "    Beng_line=Subject+Object+Verb\n",
    "    print(\"After Reconstructing the Sentence it wil  be like: \",Beng_line)\n",
    "    Beng_mean=list()\n",
    "    list_1=list()\n",
    "    str_1=''\n",
    "    #meaning creation \n",
    "    person=''\n",
    "    i=0\n",
    "    while(i<len(Subject)):\n",
    "        print('Subject')\n",
    "        str_1=str(df_xls.loc[df_xls['eng']==Subject[i].upper(),'beng']).split(' ')[4].split('\\n')[0]\n",
    "        #print(str_1.split(' ')[4].split('\\n'))\n",
    "        Beng_mean.append(str_1)\n",
    "        if(Subject[i] == 'He' or Subject[i] == 'She'  or Subject[i] == 'They'):\n",
    "            person='3rd_Person'\n",
    "        if(Subject[i] == 'I' or Subject[i] == 'We'):\n",
    "            person='1st_Person'\n",
    "        if(Subject[i] == 'You'):\n",
    "            person='2nd_Person'\n",
    "        i+=1\n",
    "    person='2nd_Person'\n",
    "    i=0\n",
    "    #if(check_class(Object[i])=='TO' or check_class(Object[i])=='IN'):\n",
    "    if('TO' in token_class or 'IN' in token_class):\n",
    "        Object.reverse()\n",
    "            #Object += [Object.pop(0)]\n",
    "            #print(Object)\n",
    "            #Object.insert(len(Object)-1, list1.pop(0))\n",
    "    #print(Object)\n",
    "    while(i<len(Object)):\n",
    "        print('Object')\n",
    "        str_1=str(df_xls.loc[df_xls['eng']==Object[i].upper(),'beng']).split(' ')[4].split('\\n')[0]\n",
    "        #print(str_1.split(' ')[4].split('\\n'))\n",
    "        Beng_mean.append(str_1)\n",
    "        i+=1\n",
    "    \n",
    "    \n",
    "    i=0\n",
    "    #for am ,i ,are\n",
    "    Pres_Aux=0\n",
    "    Past_Aux=0\n",
    "    Fut_Aux=0\n",
    "    #print(df_xls.loc[df_xls['eng']==Verb[i].upper(),'beng'])\n",
    "    while(i<len(Verb)):\n",
    "        print('Verb')\n",
    "        list_1=list(df_xls.loc[df_xls['eng']==Verb[i].upper(),'beng'])\n",
    "        str1 = ''.join(list_1)\n",
    "        #print(str1)\n",
    "        #print(type(list_1))\n",
    "        list_2=list()\n",
    "        if(check_class(Verb[i])=='VBP'):\n",
    "            list_2=str1.split(',')\n",
    "            #print(list_2)\n",
    "            if(i>=0):\n",
    "                #print('enter if i>=0')\n",
    "                list_3=list()\n",
    "                for i1 in range(0,len(list_2)):\n",
    "                    #print('enter in the loop')\n",
    "                    list_3=list_2[i1].split('-')\n",
    "                    #print(list_3)\n",
    "                    if(list_3[1]=='Simple_Present'):\n",
    "                        if(list_3[2]==person):\n",
    "                            Beng_mean.append(list_3[0])\n",
    "                    if(list_3[1]=='Aux'):\n",
    "                        if(list_3[2]=='Present'):\n",
    "                            Pres_Aux=1\n",
    "                        #if(list_3[2]=='Past'):\n",
    "                            #Past_Aux=1\n",
    "\n",
    "\n",
    "        if(check_class(Verb[i])=='VBZ'):\n",
    "            list_2=[i.split(',', 1)[0] for i in list_1]\n",
    "            #list_2=str1.split(',')\n",
    "            #print(type(list_2[0]))\n",
    "            if(i>=0):\n",
    "                #print('enter if i>=0')\n",
    "                list_3=list()\n",
    "                for i1 in range(0,len(list_2)):\n",
    "                    #print('enter in the loop')\n",
    "                    list_3=list_2[i1].split('-')\n",
    "                    #print(list_3)\n",
    "                    if(list_3[1]=='Aux'):\n",
    "                        if(list_3[2]=='Present'):\n",
    "                            Pres_Aux=1\n",
    "                        if(list_3[2]=='Past'):\n",
    "                            Past_Aux=1\n",
    "                    if(list_3[1]=='Simple_Present'):\n",
    "                        Beng_mean.append(list_3[0]) \n",
    "                    if(list_3[1]=='Present/Future_Continuous'):\n",
    "                        Beng_mean.append(list_3[0])\n",
    "        if(check_class(Verb[i])=='VBG'):\n",
    "            list_2=str1.split(',')\n",
    "            #print(list_2)\n",
    "            if(i>=0):\n",
    "                #print('enter if i>=0')\n",
    "                list_3=list()\n",
    "                for i1 in range(0,len(list_2)):\n",
    "                    #print('enter in the loop')\n",
    "                    list_3=list_2[i1].split('-')\n",
    "                    #print(list_3)\n",
    "                    if(list_3[1]=='Present_Continuous'):\n",
    "                        if(list_3[2]==person):\n",
    "                            Beng_mean.append(list_3[0])\n",
    "        if(check_class(Verb[i])=='VB'):\n",
    "            list_2=str1.split(',')\n",
    "            #print(list_2)\n",
    "            if(i>=0):\n",
    "                #print('enter if i>=0')\n",
    "                list_3=list()\n",
    "                for i1 in range(0,len(list_2)):\n",
    "                    #print('enter in the loop')\n",
    "                    list_3=list_2[i1].split('-')\n",
    "                    #print(list_3)\n",
    "                    if(list_3[1]=='Simple_Present' and list_3[2]=='2nd_Person'):\n",
    "                        Beng_mean.append(list_3[0])\n",
    "                        \n",
    "        i+=1\n",
    "    #normal meaning finding\n",
    "    '''i=0\n",
    "    while(i<len(Beng_line)):\n",
    "        Beng_mean.append(df_xls.loc[df_xls['eng']==Beng_line[i].upper(),'beng'])\n",
    "        i+=1'''\n",
    "    print(\"The English sentence is: \",txt_test)\n",
    "    print(\"The Bengali meaning is: \",Beng_mean)\n",
    "#exp done:\n",
    "#1meet me after the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_table=pd.DataFrame()\n",
    "result_table=pd.DataFrame(columns=('Input(English)','Standard Statement', 'Output(Google translator)', 'Output(Proposed System)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('output.xlsx')\n",
    "result_table.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_table.drop(result_table.index[[0]],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result matches  81.31868131868131 %\n"
     ]
    }
   ],
   "source": [
    "#or i in range(1):\n",
    "inp_eng=input('Enter English: ')\n",
    "out_GT=input('Enter GT op: ')\n",
    "out_me=input('Enter me op: ')\n",
    "out_beng=input('Enter norm op: ')\n",
    "result_table.loc[0]= [inp_eng,out_beng,out_GT,out_me]\n",
    "    \n",
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our result matches  88.88888888888889 %\n",
      "Google result matches  50.0 %\n"
     ]
    }
   ],
   "source": [
    "#result comparision\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "the_text='তুমি আমার থেকে কি আশা করছ'\n",
    "me_text='কুকুর টি খুব শান্ত'\n",
    "result=similar(the_text,me_text)\n",
    "print('Our result matches ',result*100,'%')\n",
    "\n",
    "goggle_text='কুকুর তাই শীতল তাই'\n",
    "result=similar(the_text,goggle_text)\n",
    "print('Google result matches ',result*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input(English)</th>\n",
       "      <th>Standard Statement</th>\n",
       "      <th>Output(Google translator)</th>\n",
       "      <th>Output(Proposed System)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>after high school, sauvik moves to jaipur</td>\n",
       "      <td>উচ্চ বিদ্যালয় শেষের পরে সৌভিক জয়পুরে চলে য।য়</td>\n",
       "      <td>হাই স্কুল পর, সউয়াইচ জীপ থেকে চলে যায়</td>\n",
       "      <td>উচ্চ বিদ্যালয় সৌভিক পরে জয়পুর এতে চলে য।য়</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am going to farmland</td>\n",
       "      <td>আমি কৃষিজমিতে যাচ্ছি</td>\n",
       "      <td>আমি কৃষিতে যাচ্ছি</td>\n",
       "      <td>আমি কৃষিজমি এতে যাচ্ছি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meet me after the class</td>\n",
       "      <td>ক্লাসের পরে আমায় সাক্ষাৎ কর</td>\n",
       "      <td>বর্গ পরে আমার দেখা</td>\n",
       "      <td>ক্লাস টি পরে আমায় সাক্ষাৎ কর</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>give me some time</td>\n",
       "      <td>আমায় কিছু সময় দাও</td>\n",
       "      <td>আমাকে কিছু সময় দিতে</td>\n",
       "      <td>আমায় কিছু সময় দাও</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the dog is so cool</td>\n",
       "      <td>কুকুরটা খুব শান্ত</td>\n",
       "      <td>কুকুর তাই শীতল তাই</td>\n",
       "      <td>কুকুর টি খুব শান্ত</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are you expecting from me</td>\n",
       "      <td>তুমি আমার থেকে কি আশা করছ</td>\n",
       "      <td>তুমি আমার কাছ থেকে কি আশা করছ</td>\n",
       "      <td>তুমি আমার থেকে কি আশা করছ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I am going to school</td>\n",
       "      <td>আমি বিদ্যালয়ে যাচ্ছি</td>\n",
       "      <td>আমি স্কুলে যাচ্ছি</td>\n",
       "      <td>আমি বিদ্যালয় এতে যাচ্ছি</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Input(English)  \\\n",
       "0  after high school, sauvik moves to jaipur   \n",
       "1                     I am going to farmland   \n",
       "2                    meet me after the class   \n",
       "3                          give me some time   \n",
       "4                         the dog is so cool   \n",
       "5             What are you expecting from me   \n",
       "6                       I am going to school   \n",
       "\n",
       "                               Standard Statement  \\\n",
       "0  উচ্চ বিদ্যালয় শেষের পরে সৌভিক জয়পুরে চলে য।য়   \n",
       "1                            আমি কৃষিজমিতে যাচ্ছি   \n",
       "2                    ক্লাসের পরে আমায় সাক্ষাৎ কর   \n",
       "3                             আমায় কিছু সময় দাও   \n",
       "4                               কুকুরটা খুব শান্ত   \n",
       "5                       তুমি আমার থেকে কি আশা করছ   \n",
       "6                           আমি বিদ্যালয়ে যাচ্ছি   \n",
       "\n",
       "                 Output(Google translator)  \\\n",
       "0  হাই স্কুল পর, সউয়াইচ জীপ থেকে চলে যায়   \n",
       "1                        আমি কৃষিতে যাচ্ছি   \n",
       "2                       বর্গ পরে আমার দেখা   \n",
       "3                     আমাকে কিছু সময় দিতে   \n",
       "4                       কুকুর তাই শীতল তাই   \n",
       "5            তুমি আমার কাছ থেকে কি আশা করছ   \n",
       "6                        আমি স্কুলে যাচ্ছি   \n",
       "\n",
       "                       Output(Proposed System)  \n",
       "0  উচ্চ বিদ্যালয় সৌভিক পরে জয়পুর এতে চলে য।য়  \n",
       "1                       আমি কৃষিজমি এতে যাচ্ছি  \n",
       "2                ক্লাস টি পরে আমায় সাক্ষাৎ কর  \n",
       "3                          আমায় কিছু সময় দাও  \n",
       "4                           কুকুর টি খুব শান্ত  \n",
       "5                    তুমি আমার থেকে কি আশা করছ  \n",
       "6                     আমি বিদ্যালয় এতে যাচ্ছি  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input(English)</th>\n",
       "      <th>Output(Google translator)</th>\n",
       "      <th>Output(Proposed System)</th>\n",
       "      <th>Output(Bengali Regional)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>after high school, sauvik moves to jaipur</td>\n",
       "      <td>হাই স্কুল পর, সউয়াইচ জীপ থেকে চলে যায়</td>\n",
       "      <td>উচ্চ বিদ্যালয় সৌভিক পরে জয়পুর এতে চলে য।য়</td>\n",
       "      <td>উচ্চ বিদ্যালয় শেষের পরে সৌভিক জয়পুরে চলে য।য়</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am going to farmland</td>\n",
       "      <td>আমি কৃষিতে যাচ্ছি</td>\n",
       "      <td>আমি কৃষিজমি এতে যাচ্ছি</td>\n",
       "      <td>আমি কৃষিজমিতে যাচ্ছি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meet me after the class</td>\n",
       "      <td>বর্গ পরে আমার দেখা</td>\n",
       "      <td>ক্লাস টি পরে আমায় সাক্ষাৎ কর</td>\n",
       "      <td>ক্লাসের পরে আমায় সাক্ষাৎ কর</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>give me some time</td>\n",
       "      <td>আমাকে কিছু সময় দিতে</td>\n",
       "      <td>আমায় কিছু সময় দাও</td>\n",
       "      <td>আমায় কিছু সময় দাও</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the dog is so cool</td>\n",
       "      <td>কুকুর তাই শীতল তাই</td>\n",
       "      <td>কুকুর টি খুব শান্ত</td>\n",
       "      <td>কুকুরটা খুব শান্ত</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Input(English)  \\\n",
       "0  after high school, sauvik moves to jaipur   \n",
       "1                     I am going to farmland   \n",
       "2                    meet me after the class   \n",
       "3                          give me some time   \n",
       "4                         the dog is so cool   \n",
       "\n",
       "                 Output(Google translator)  \\\n",
       "0  হাই স্কুল পর, সউয়াইচ জীপ থেকে চলে যায়   \n",
       "1                        আমি কৃষিতে যাচ্ছি   \n",
       "2                       বর্গ পরে আমার দেখা   \n",
       "3                     আমাকে কিছু সময় দিতে   \n",
       "4                       কুকুর তাই শীতল তাই   \n",
       "\n",
       "                       Output(Proposed System)  \\\n",
       "0  উচ্চ বিদ্যালয় সৌভিক পরে জয়পুর এতে চলে য।য়   \n",
       "1                       আমি কৃষিজমি এতে যাচ্ছি   \n",
       "2                ক্লাস টি পরে আমায় সাক্ষাৎ কর   \n",
       "3                          আমায় কিছু সময় দাও   \n",
       "4                           কুকুর টি খুব শান্ত   \n",
       "\n",
       "                         Output(Bengali Regional)  \n",
       "0  উচ্চ বিদ্যালয় শেষের পরে সৌভিক জয়পুরে চলে য।য়  \n",
       "1                            আমি কৃষিজমিতে যাচ্ছি  \n",
       "2                    ক্লাসের পরে আমায় সাক্ষাৎ কর  \n",
       "3                             আমায় কিছু সময় দাও  \n",
       "4                               কুকুরটা খুব শান্ত  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_table.loc[0]= ['after high school, sauvik moves to jaipur','উচ্চ বিদ্যালয় শেষের পরে সৌভিক জয়পুরে চলে য।য়','হাই স্কুল পর, সউয়াইচ জীপ থেকে চলে যায়','উচ্চ বিদ্যালয় সৌভিক পরে জয়পুর এতে চলে য।য়']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_table.loc[1]=['I am going to farmland','আমি কৃষিজমিতে যাচ্ছি','আমি কৃষিতে যাচ্ছি','আমি কৃষিজমি এতে যাচ্ছি']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_table.loc[2]=['meet me after the class','ক্লাসের পরে আমায় সাক্ষাৎ কর','বর্গ পরে আমার দেখা','ক্লাস টি পরে আমায় সাক্ষাৎ কর',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_table.loc[3]=['give me some time','আমায় কিছু সময় দাও','আমাকে কিছু সময় দিতে','আমায় কিছু সময় দাও']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_table.loc[4]=['the dog is so cool','কুকুরটা খুব শান্ত','কুকুর তাই শীতল তাই','কুকুর টি খুব শান্ত']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_table.loc[5]=['What are you expecting from me','তুমি আমার থেকে কি আশা করছ','তুমি আমার কাছ থেকে কি আশা করছ','তুমি আমার থেকে কি আশা করছ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_table.loc[6]=['I am going to school','আমি বিদ্যালয়ে যাচ্ছি','আমি স্কুলে যাচ্ছি','আমি বিদ্যালয় এতে যাচ্ছি']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_table.loc[7]=['the dog is so cool','কুকুরটা খুব শান্ত','কলেজ পরে কোচিং ক্লাসে যান','কুকুর টি খুব শান্ত']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_table.loc[8]=['the dog is so cool','কুকুরটা খুব শান্ত','কুকুর তাই শীতল তাই','কুকুর টি খুব শান্ত']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_table.loc[9]=['the dog is so cool','কুকুরটা খুব শান্ত','কুকুর তাই শীতল তাই','কুকুর টি খুব শান্ত']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_table.loc[10]=['the dog is so cool','কুকুরটা খুব শান্ত','কুকুর তাই শীতল তাই','কুকুর টি খুব শান্ত']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
